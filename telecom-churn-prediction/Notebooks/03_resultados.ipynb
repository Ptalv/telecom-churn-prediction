{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ¿Qué pasos del plan se realizaron y qué pasos se omitieron?\n",
    "\n",
    "Los pasos que seguí para resolver esta tarea fueron los siguientes:\n",
    "\n",
    "1. Cargué y exploré los datos, revisé la correlación entre las variables e identifiqué que la variable objetivo tenía un desbalance bastante marcado (había muchos más \"No\" que fechas de término).\n",
    "2. Creé la variable objetivo binarizando la columna EndDate.\n",
    "3. Luego pasé a la parte de procesamiento, donde dividí cuáles eran las variables numéricas y categóricas. Después, usé ColumnTransformer para aplicar one-hot encoding e imputación.\n",
    "4. Utilicé SMOTE dentro del pipeline para generar datos sintéticos de la clase minoritaria, manejando así el desbalance.\n",
    "5. Probé el modelo LightGBMClassifier sin ajuste de hiperparámetros. Posteriormente, lo evalué con las métricas AUC, F1-score y accuracy.\n",
    "6. Apliqué GridSearchCV para el ajuste de hiperparámetros.\n",
    "7. Grafiqué la curva ROC y comparé los resultados del modelo ya ajustado usando predict() y predict_proba()\n",
    "\n",
    "    Omití los siguientes pasos:\n",
    "\n",
    "- Pruebas con otros modelos: ya que LightGBM alcanzó un rendimiento ejemplar.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "    ¿Qué dificultades encontré y cómo logré resolverlas?\n",
    "\n",
    "Durante esta tarea, me di cuenta de que estaba evaluando incorrectamente el modelo, ya que usaba AUC-ROC con predicciones binarias en lugar de probabilísticas, lo cual disminuía la métrica AUC. Luego lo corregí, comparando ambos enfoques y eligiendo el correcto.\n",
    "\n",
    "El desbalance de clases también fue un reto, ya que tuve que investigar cómo aplicar una técnica para ajustar las clases. Finalmente, resolví el problema instalando el módulo imblearn y aplicando SMOTE.\n",
    "\n",
    "---\n",
    "\n",
    "    ¿Cuáles fueron algunos de los pasos clave para resolver la tarea?\n",
    "\n",
    "- El uso correcto de pipelines fue clave en este proyecto. Incluir SMOTE, el preprocesador y el modelo dentro del mismo pipeline evitó que se filtraran datos.\n",
    "- La optimización de hiperparámetros con GridSearchCV fue determinante. Me ayudó a encontrar la mejor configuración del modelo y así alcanzar una buena métrica AUC-ROC.\n",
    "\n",
    "---\n",
    "\n",
    "    ¿Cuál es tu modelo final y qué nivel de calidad tiene?\n",
    "\n",
    "Modelo final:\n",
    "\n",
    "LightGBMClassifier dentro de un Pipeline con preprocesamiento de datos categóricos y numéricos, SMOTE para balancear las clases e hiperparámetros optimizados vía GridSearchCV\n",
    "\n",
    "### Rendimiento en la prueba:\n",
    "\n",
    "- AUC-ROC (predict_proba): 0.9108\n",
    "- F1-Score: 0.7115\n",
    "- Accuracy: 0.8538\n",
    "\n",
    "Este rendimiento indica que el modelo predice correctamente la probabilidad de cancelación en un 91% de los casos, con un buen equilibrio entre precisión y recuperación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
